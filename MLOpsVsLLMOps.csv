'Lifecycle Stage', 'MLOps', 'LLMOps'
'Data Collection', 'Structured/semistructured data', 'Vast unstructured data (text from web, books, forums)'
'Data Preparation', 'Feature engineering, cleaning, normalization', 
'Model Training', 'Lightweight to moderately heavy; task-specific models', 'Pretraining on massive datasets using distributed computing (e.g., GPUs/TPUs, Horovod)'
'Experimentation', 'Trying out different ML models and tuning','Involves large-scale hyperparameter tuning and scaling across GPUs'
'Fine-tuning','Optional or lightweight fine-tuning for specific tasks','Crucial step; applies to downstream tasks using domain-specific data (e.g., summarization)'
'Validation','Accuracy, precision, recall, F1 score, confusion matrix','Human eval, Bilingual Evaluation Understudy, Recall-Oriented Understudy for Gisting Evaluation, bias/toxicity checks, alignment evaluation'
'Deployment', 'Deployed via REST APIs, edge devices, batch pipelines', 'Requires GPU inference, optimized serving (e.g., quantization, distillation, Triton inference)'
'Monitoring', 'Drift detection, accuracy drop, system errors', 'Bias detection, hallucination tracking, latency, prompt evaluation, Reinforcement learning with Human feedback (RLHF)'
'Maintenance', 'Retraining with new data periodically or on drift', 'Continual learning, LoRA, adapter layers, re-alignment to changing usage patterns'
'Tooling', 'MLflow, Kubeflow, TFX, Airflow, Flyte', 'Hugging Face Transformers, OpenAI API, DeepSpeed, LangFuse, LangChain, etc'
